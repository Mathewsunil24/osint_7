ğŸ›°ï¸ OSINT Lab 7 â€“ Automated Social Media OSINT Pipeline
ğŸ“˜ Project Overview

This project implements an automated OSINT (Open-Source Intelligence) pipeline that collects, processes, and analyzes social media data from multiple platforms, including Reddit and Twitter.

ğŸš€ Features

ğŸŒ Multi-platform data collection (Reddit & Twitter)

ğŸ§¹ Automated data cleaning and preprocessing

ğŸ§  Sentiment analysis using TextBlob

ğŸ“ˆ Word cloud and sentiment visualization

ğŸ’¾ SQLite database storage

âš¡ Simple setup with .env for API keys

âš™ï¸ Setup Instructions
1ï¸âƒ£ Clone the Repository
git clone https://github.com/Mathewsunil24/osint_7.git
cd osint_7

2ï¸âƒ£ Create Virtual Environment
python -m venv osint_env


Activate it:

Windows

osint_env\Scripts\activate


Linux/Mac

source osint_env/bin/activate

3ï¸âƒ£ Install Dependencies
pip install -r requirements.txt

4ï¸âƒ£ Set Up Environment Variables

Create a .env file in your project folder and add your keys:

REDDIT_CLIENT_ID=your_reddit_client_id
REDDIT_CLIENT_SECRET=your_reddit_secret
TWITTER_BEARER_TOKEN=your_twitter_bearer_token

5ï¸âƒ£ Run the Pipeline
python main.py

ğŸ”‘ API Keys Required

ğŸ¦ Twitter API Bearer Token

ğŸ‘½ Reddit Client ID and Secret

âš ï¸ Note: Make sure your API credentials are stored safely in the .env file and never shared publicly.

ğŸ“‚ Project Structure
osint_pipeline/
â”œâ”€â”€ collectors/          # Platform-specific data collectors
â”œâ”€â”€ utils/               # Visualization and helper scripts
â”œâ”€â”€ data/                # Database and generated images
â”œâ”€â”€ main.py              # Main pipeline
â”œâ”€â”€ requirements.txt     # Dependencies
â””â”€â”€ README.md            # Project documentation

ğŸ“Š Output

After successful execution:

Reddit and Twitter data are stored in data/

Generated visualizations:

reddit_wordcloud.png, reddit_sentiment.png

twitter_wordcloud.png, twitter_sentiment.png
