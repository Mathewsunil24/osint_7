ğŸ•µï¸â€â™‚ï¸ OSINT Lab 7 - Automated Reddit & Twitter OSINT Pipeline
ğŸ“˜ Project Overview

This project implements an automated OSINT (Open Source Intelligence) pipeline that collects, processes, and analyzes public social media data from Reddit and Twitter.
It performs data cleaning, sentiment analysis, and visualization (WordCloud & Sentiment Graph), and stores all collected data in a SQLite database.

ğŸš€ Features

âœ… Reddit data collection using API
âœ… Twitter data collection (with rate-limit handling)
âœ… Sentiment analysis using TextBlob
âœ… WordCloud generation from text data
âœ… Sentiment visualization (Positive, Negative, Neutral)
âœ… SQLite database integration for structured storage
âœ… Easy modular structure (collectors, utils, data)

âš™ï¸ Setup Instructions
1ï¸âƒ£ Clone the repository
git clone https://github.com/Mathewsunil24/osint_8.git
cd osint_8/osint_pipeline

2ï¸âƒ£ Create virtual environment
python -m venv osint_env
osint_env\Scripts\activate   # for Windows
# OR
source osint_env/bin/activate   # for Linux/Mac

3ï¸âƒ£ Install dependencies
pip install -r requirements.txt

4ï¸âƒ£ Set up environment variables

Create a .env file in your osint_pipeline/ folder with the following values:

REDDIT_CLIENT_ID=your_reddit_client_id
REDDIT_CLIENT_SECRET=your_reddit_secret
REDDIT_USER_AGENT=your_app_name
TWITTER_BEARER_TOKEN=your_twitter_bearer_token

â–¶ï¸ Run the Pipeline
Collect Reddit Data
python -m collectors.reddit_collector

Collect Twitter Data
python -m collectors.twitter_collector

Visualize Data (WordCloud + Sentiment Graph)
python -m utils.visualize

Check Database
python -m utils.db_viewer

ğŸ§© Project Structure
osint_pipeline/
â”œâ”€â”€ collectors/
â”‚   â”œâ”€â”€ reddit_collector.py     # Reddit data collection
â”‚   â”œâ”€â”€ twitter_collector.py    # Twitter data collection
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ visualize.py            # WordCloud + Sentiment visualization
â”‚   â”œâ”€â”€ db_viewer.py            # Check stored data in SQLite
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ reddit_results.json
â”‚   â”œâ”€â”€ twitter_results.json
â”‚   â”œâ”€â”€ osint_pipeline.db
â”‚
â”œâ”€â”€ main.py                     # Combined pipeline script
â”œâ”€â”€ requirements.txt            # Dependencies
â””â”€â”€ .env                        # API keys

ğŸ§  Technologies Used

Python 3.x

PRAW â€“ Reddit API wrapper

Requests / Tweepy â€“ Twitter API access

TextBlob â€“ Sentiment analysis

Matplotlib â€“ Visualization

WordCloud â€“ Word cloud generation

SQLite3 â€“ Local database storage

ğŸ“Š Output Samples

data/reddit_wordcloud.png â†’ Word cloud from Reddit posts

data/reddit_sentiment.png â†’ Sentiment analysis chart

data/twitter_wordcloud.png â†’ Word cloud from Twitter tweets

data/twitter_sentiment.png â†’ Twitter sentiment chart

âš ï¸ Notes

Twitter API may show â€œ429 Too Many Requestsâ€ â€” this is a rate limit issue; try again later.

Make sure .env file is correctly filled before running any collector.

Reddit visualization works completely. Twitter visualization depends on successful API fetch.